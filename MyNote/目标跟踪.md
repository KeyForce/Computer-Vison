[TOC]

# 目标检测

## Cascade-RCNN

### ResNet

### ResNeXt

### HRNet



## 训练技巧

### Warmup LR

### 多尺度训练



## 推理技巧

### TTA（Test Time Augmentation）

### 多尺度推理





## 损失函数



![目标检测回归损失函数简介：SmoothL1/IoU/GIoU/DIoU/CIoU Loss](J:\Main Project\Computer-Vison\MyNote\image\v2-a7908704f0963013ee0f29807b43a940_1200x500.jpg)

### 1.IoU Loss

交并比

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589025634590.svg)

![img](J:\Main Project\Computer-Vison\MyNote\image\13942301-2776160ba9791aaa.webp)

```
import numpy as np

def Iou(box1, box2)
	xmin1, ymin1, xmax1, ymax1 = box1
	xmin2, ymin2, xmax2, ymax2 = box2
	# 获取矩形框交集对应的左上角和右下角的坐标（intersection）
    xx1 = np.max([xmin1, xmin2])
    yy1 = np.max([ymin1, ymin2])
    xx2 = np.min([xmax1, xmax2])
    yy2 = np.min([ymax1, ymax2])
    # 计算两个矩形框面积
    area1 = (xmax1-xmin1) * (ymax1-ymin1) 
    area2 = (xmax2-xmin2) * (ymax2-ymin2)
    # 计算交集面积
    inter_area = (np.max([0, xx2-xx1])) * (np.max([0, yy2-yy1]))　
    # 计算交并比
	iou = inter_area / (area1+area2-inter_area+1e-6)
	
	return iou
```

### 2.GIOU  Loss

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027488110.svg)

*上面公式的意思是：先计算两个框的最小闭包区域面积* ![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027503675.svg) *(通俗理解：**同时包含了预测框和真实框**的最小框的面积)，再计算出IoU，再计算闭包区域中不属于两个框的区域占闭包区域的比重，最后用IoU减去这个比重得到GIoU。*

```
def Giou(rec1,rec2):
    #分别是第一个矩形左右上下的坐标
    x1,x2,y1,y2 = rec1 
    x3,x4,y3,y4 = rec2
    iou = Iou(rec1,rec2)
    area_C = (max(x1,x2,x3,x4)-min(x1,x2,x3,x4))*(max(y1,y2,y3,y4)-min(y1,y2,y3,y4))
    area_1 = (x2-x1)*(y1-y2)
    area_2 = (x4-x3)*(y3-y4)
    sum_area = area_1 + area_2

    w1 = x2 - x1   #第一个矩形的宽
    w2 = x4 - x3   #第二个矩形的宽
    h1 = y1 - y2
    h2 = y3 - y4
    W = min(x1,x2,x3,x4)+w1+w2-max(x1,x2,x3,x4)    #交叉部分的宽
    H = min(y1,y2,y3,y4)+h1+h2-max(y1,y2,y3,y4)    #交叉部分的高
    Area = W*H    #交叉的面积
    add_area = sum_area - Area    #两矩形并集的面积

    end_area = (area_C - add_area)/area_C    #闭包区域中不属于两个框的区域占闭包区域的比重
    giou = iou - end_area
    return giou
```

### 3.DIoU Loss

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027730926.svg)

其中， ![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027763479.svg) ， ![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027763480.svg) 分别代表了预测框和真实框的中心点，且 ![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027763481.svg) 代表的是计算两个中心点间的欧式距离。 ![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589027763504.svg) 代表的是能够同时包含预测框和真实框的**最小闭包区域**的对角线距离。

![img](J:\Main Project\Computer-Vison\MyNote\image\v2-1e4b54001c4abdf392fe9d4877c83972_720w.jpg)

```
def Diou(bboxes1, bboxes2):
    rows = bboxes1.shape[0]
    cols = bboxes2.shape[0]
    dious = torch.zeros((rows, cols))
    if rows * cols == 0:#
        return dious
    exchange = False
    if bboxes1.shape[0] > bboxes2.shape[0]:
        bboxes1, bboxes2 = bboxes2, bboxes1
        dious = torch.zeros((cols, rows))
        exchange = True
    # #xmin,ymin,xmax,ymax->[:,0],[:,1],[:,2],[:,3]
    w1 = bboxes1[:, 2] - bboxes1[:, 0]
    h1 = bboxes1[:, 3] - bboxes1[:, 1] 
    w2 = bboxes2[:, 2] - bboxes2[:, 0]
    h2 = bboxes2[:, 3] - bboxes2[:, 1]
    
    area1 = w1 * h1
    area2 = w2 * h2

    center_x1 = (bboxes1[:, 2] + bboxes1[:, 0]) / 2 
    center_y1 = (bboxes1[:, 3] + bboxes1[:, 1]) / 2 
    center_x2 = (bboxes2[:, 2] + bboxes2[:, 0]) / 2
    center_y2 = (bboxes2[:, 3] + bboxes2[:, 1]) / 2

    inter_max_xy = torch.min(bboxes1[:, 2:],bboxes2[:, 2:]) 
    inter_min_xy = torch.max(bboxes1[:, :2],bboxes2[:, :2]) 
    out_max_xy = torch.max(bboxes1[:, 2:],bboxes2[:, 2:]) 
    out_min_xy = torch.min(bboxes1[:, :2],bboxes2[:, :2])

    inter = torch.clamp((inter_max_xy - inter_min_xy), min=0)
    inter_area = inter[:, 0] * inter[:, 1]
    inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2
    outer = torch.clamp((out_max_xy - out_min_xy), min=0)
    outer_diag = (outer[:, 0] ** 2) + (outer[:, 1] ** 2)
    union = area1+area2-inter_area
    dious = inter_area / union - (inter_diag) / outer_diag
    dious = torch.clamp(dious,min=-1.0,max = 1.0)
    if exchange:
        dious = dious.T
    return dious
```

### 4.RepLoss 优化解决密集遮挡问题

![这里写图片描述](J:\Main Project\Computer-Vison\MyNote\image\20180904193957569.png)!



![Repulsion Loss](J:\Main Project\Computer-Vison\MyNote\image\20180904194930895-1589028558743.png)

# 目标跟踪

## DeepSort

**匈牙利算法（Hungarian Algorithm）** & **KM算法**

匈牙利算法用于解决二分图的**最大匹配**问题

算法步骤（假设矩阵为NxN方阵）：

1. 对于矩阵的每一行，减去其中最小的元素
2. 对于矩阵的每一列，减去其中最小的元素
3. 用最少的水平线或垂直线覆盖矩阵中所有的0
4. 如果线的数量等于N，则找到了最优分配，算法结束，否则进入步骤5
5. 找到没有被任何线覆盖的最小元素，每个**没被线覆盖的行**减去这个元素，每个**被线覆盖的列**加上这个元素，返回步骤3

在DeepSORT中，匈牙利算法用来将前一帧中的**跟踪框tracks**与当前帧中的**检测框detections**进行关联，通过**外观信息（appearance information）**和**马氏距离（Mahalanobis distance）**或者余弦距离，或者**IOU**来计算代价矩阵。



**卡尔曼滤波（Kalman Filter）**

卡尔曼滤波分为两个阶段：(1) **预测**track在下一时刻的位置，(2) 基于detection来**更新**预测的位置。



**DeepSort工作流程**

检测器得到bbox → 生成detections → 卡尔曼滤波预测→ 使用匈牙利算法将预测后的tracks和当前帧中的detecions进行匹配（级联匹配和IOU匹配） → 卡尔曼滤波更新

```
Frame 0：检测器检测到了3个detections，当前没有任何tracks，将这3个detections初始化为tracks                                                                                                   Frame 1：检测器又检测到了3个detections，对于Frame 0中的tracks，先进行预测得到新的tracks，然后使用匈牙利算法将新的tracks与detections进行匹配，得到(track, detection)匹配对，最后用每对中的detection更新对应的track
```



## MOTDT

其**核心思想**是同时从Object detection和object tracking里同时生成object candidates (bbox)，设计一种评分机制以选择最终的Candidates（如下图）。这里的intuition是detection和tracking是相辅相成的，比如detection里的high confidence结果可以防止tracking drifts，而tracking可以降低detection带来的偶然的不准确性。

<img src="J:\Main Project\Computer-Vison\MyNote\image\v2-6d90d43638dd0807f69c95845254524c_b.jpg" alt="img" style="zoom:80%;" />



## 级联匈牙利算法

## 余弦距离 马氏距离






















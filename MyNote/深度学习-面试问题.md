[TOC]

### 1.介绍Faster RCNN的流程及损失函数，为什么这样设计损失函数

![img](image/v2-c0172be282021a1029f7b72b51079ffe_hd.jpg)

**流程**

* Backbone。先通过主干网络提取特征图
* Region Proposal Networks。在通过RPN网络判断anchors属于前景还是背景，这里RPN网络包括两个部分，Anchor的生成和两层的卷积层
* Roi Ailing。该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。
* Classification。利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。

**损失函数**

* Smooth L1 Loss（边框回归损失）

  融合L2损失：f(x)=x^2 ，L1损失：f(x)=|x|，构造成分段函数。

  L2损失对于比较大的误差的惩罚很高

  L1损失在0点处导数不存在，因此可能会影响收敛

  ![img](image/201812121325127.png)

* Cross Entropy Loss（分类损失）

### 2.介绍YOLO的流程

* 将图片Resize成448\*448，图片分割得到7\*7网格(cell)

* CNN提取特征和预测：卷积负责提特征。全链接负责预测：

  **a**) 7\*7\*2=98个bounding box(bbox) 的坐标![[公式]](https://www.zhihu.com/equation?tex=x_%7Bcenter%7D%2Cy_%7Bcenter%7D%2Cw%2Ch) 和是否有物体的conﬁdence 。 

  **b)** 7\*7=49个cell所属20个物体的概率。

* 过滤bbox（通过nms）

### 3.说一说常见的正则化手段，L1和L2正则化的不同

L1最小绝对偏差

L2最小二乘误差 

L2对大数，对异常值更敏感

### 4.说一下交叉熵损失函数，什么是交叉熵

二分类

![[公式]](image/equation.svg)

其中：
- y——表示样本的label，正类为1，负类为0
- p——表示样本预测为正的概率

多分类

![[公式]](image/equation-1565940522253.svg)

其中：

- ![[公式]](image/equation-1565940508633.svg) ——类别的数量；
- ![[公式]](image/equation-1565940508639.svg) ——指示变量（0或1）,如果该类别和样本的类别相同就是1，否则是0；
- ![[公式]](image/equation-1565940508639.svg) ——对于观测样本属于类别 ![[公式]](image/equation-1565940508745.svg) 的预测概率。

### 5.CNN为什么要做卷积，为什么要有步长，为什么不用全连接层，它的反向传播是什么？

* 卷积就是一个滤波器，可调整的**滤波器**是 CNN 的**“卷积”**那部分；如何**调整滤波器**则是 CNN 的**“神经网络”**那部分。

* 步长小，提取的特征会更全面，不会遗漏太多信息。但同时可能造成计算量增大，甚至过拟合等问题。步长大，计算量会下降，但很有可能错失一些有用的特征。

* 全连接层（fully connected layers，FC）在整个卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数层等操作是将原始数据映射到**特征空间**的话，全连接层则起到将学到的“分布式特征表示”映射到**样本标记空间**的作用

### 6.给一张散点图，怎么做方差最大回归

### 7.怎么处理样本的不均衡，尤其是各个图像检测模型中

* OHEM（online hard example mining）在线困难样本挖掘

  OHEM算法，它在训练过程中自动选择困难样本，其核心思想是根据输入样本的损失值进行筛选，筛选出困难样本，然后将筛选得到的这些样本应用在SGD中。

* Focal Loss

  Focal loss主要是为了解决one-stage目标检测中正负样本比例严重失衡的问题。

### 8.过拟合怎么解决

* Early stopping
* 数据集扩增  有时候往往拥有更多的数据胜过一个好的模型

* 正则化方法

### 9.deeplab，CRF后处理的目的

CRF-条件随机场，利用crf修饰分割所得的图像边缘，CRF是后处理，是不参与训练的，在测试的时候对feature map做完CRF后，再双线性插值resize到原图尺寸

- 

### 11.多标签分类怎么解决，从损失函数角度考虑

### 12.俩个问题，怎么检测过拟合，怎么减少过拟合

* 交叉验证目的：

  选出最优参数的模型。模型建立后，调参数是个很费时的过程，通过交叉验证我们可以得出最优参数的模型。 
  1.1 准备候选模型，M1，M2，M3，……（模型框架一致，只是参数不同） 
  1.2 对于每个模型，分别进行交叉验证，返回该模型的准确率或者错误率等信息（自己选择是计算accuracy还是error），其返回应该是交叉验证后得出的均值。 
  1.3 通过比较不同模型的accuracy或error，选择最佳模型。

* 交叉验证分类：

  留P验证（Leave-p-out Cross Validation)、k-fold交叉验证（K-fold Cross Validation）等。 
  2.1 留p验证（LpO CV）是指训练集上随机选择p个样本作为测试集，其余作为子训练集。时间复杂度为CpNCNp，是阶乘的复杂度，不可取。 
  2.2 k-fold交叉验证就是将数据集平均分割成k份，依次选择一份作为测试集，其余作为子训练集，最后将得到的k个accuracy取平均。通常K取10，也就是经常听到的10折交叉验证。

### 13.Focal loss  交叉熵

**交叉熵**

![[公式]](image/equation-1565940522253.svg)

**Softmax** (**归一化指数函数**)

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589354991885.svg)

**Sigmoid**

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589355026514.svg)

Focal loss主要是为了解决one-stage目标检测中正负样本比例严重失衡的问题。该损失函数降低了大量简单负样本在训练中所占的权重，也可理解为一种困难样本挖掘。

Focal loss是在交叉熵损失函数基础上进行的修改

![img](image/1055519-20180818162755861-24998254.png)

![1055519-20180818174944824-933422059](image/1055519-20180818174944824-933422059.png)

其中gamma>0使得减少易分类样本的损失。使得更关注于困难的、错分的样本。

平衡因子alpha，用来平衡正负样本本身的比例不均：文中alpha取0.25，即正样本要比负样本占比小，这是因为**负例易分**。

只添加alpha虽然可以平衡正负样本的重要性，但是无法解决简单与困难样本的问题。

**gamma调节简单样本权重降低的速率**，当gamma为0时即为交叉熵损失函数，当gamma增加时，调整因子的影响也在增加。实验发现**gamma为2是最优**。

### 14.反向传播算法

误差反向传播

反向传播算法（BP 算法）主要由两个阶段组成：激励传播与权重更新。

**第1阶段：激励传播**

每次迭代中的传播环节包含两步：

1. （前向传播阶段）将训练输入送入网络以获得激励响应；
2. （反向传播阶段）将激励响应同训练输入对应的目标输出求差，从而获得输出层和隐藏层的响应误差。

**第2阶段：权重更新**

对于每个突触上的权重，按照以下步骤进行更新：

1. 将输入激励和响应误差相乘，从而获得权重的梯度；
2. 将这个梯度乘上一个比例并取反后加到权重上。

这个比例（百分比）将会影响到训练过程的速度和效果，因此成为“训练因子”。梯度的方向指明了误差扩大的方向，因此在更新权重的时候需要对其取反，从而减小权重引起的误差。

第 1 和第 2 阶段可以反复循环迭代，直到网络对输入的响应达到满意的预定的目标范围为止。

### 15.如何解决训练样本少的问题

1.利用预训练模型进行迁移微调（fine-tuning），预训练模型通常在特征上拥有很好的语义表达。

2.单样本或者少样本学习（one-shot，few-shot learning），这种方式适用于样本类别远远大于样本数量的情况等极端数据集。例如有 1000 个类别，每个类别只提供 1-5 个样本。少样本学习同样也需要借助预训练模型，但有别于微调的在于，微调通常仍然在学习不同类别的语义，而少样本学习通常需要学习样本之间的距离度量。例如孪生网络（Siamese Neural Networks）就是通过训练两个同种结构的网络来判别输入的两张图片是否属于同一类。

### 16.对 fine-tuning (微调模型的理解)，为什么要修改最后几层神经网络权值？

1.CNN 中更靠近底部的层（定义模型时先添加到模型中的层）编码的是更加通用的可复用特征，而更靠近顶部的层（最后添加到模型中的层）编码的是更专业业化的特征。微调这些更专业化的特征更加有用，它更代表了新数据集上的有用特征。 

2.训练的参数越多，过拟合的风险越大。很多 SOTA 模型拥有超过千万的参数，在一个不大的数据集上训练这么多参数是有过拟合风险的，除非你的数据集像 Imagenet 那样大。

### 17.线性因素和非线性因素各指什么（映射方式）

线性1+1=2 **齐次性**和**可加性**

非线性1+1不等于2

### 18.为什么要有激活函数

无激活函数

![img](image/ef7eb0f56730058e1100dd6605eb2a25_hd.jpg)

有激活函数







![img](image/fab8a7ae1cb63992f70e160d7f03c067_hd.jpg)

### 19.t-SNE算法



### 20.两分布间距离的度量：MMD、KL散度、Wasserstein 对比

都可以衡量两个样本之间的差异，KL散度度量的不是距离，而是一种信息损失。最大均值差异（Maximum mean discrepancy，MMD），度量在再生希尔伯特空间中两个分布的距离，是一种核学习方法（先经过一个函数的变换）

### 22.NMS SoftNMS

```
NMS
```

**算法逻辑:**
输入: nn 行 44 列的候选框数组, 以及对应的 nn 行 11 列的置信度数组.
输出: mm 行 44 列的候选框数组, 以及对应的 mm 行 11 列的置信度数组, mm 对应的是去重后的候选框数量
算法流程:

1. 计算 nn 个候选框的面积大小
2. 对置信度进行排序, 获取排序后的下标序号, 即采用`argsort`
3. 将当前置信度最大的框加入返回值列表中
4. 获取当前置信度最大的候选框与其他任意候选框的相交面积
5. 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除.
6. 对剩余的框重复以上过程

```python
import numpy as np

def py_cpu_nms(dets, thresh):
    """Pure Python NMS baseline."""
    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]
    scores = dets[:, 4]

    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    
	#打分从大到小排列，取index
    order = scores.argsort()[::-1] 

    keep = []
    while order.size > 0:
        #order[0]是当前分数最大的窗口，肯定保留
        i = order[0]
        keep.append(i)
        
		#计算窗口i与其他所有窗口的交叠部分的面积
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])

        w = np.maximum(0.0, xx2 - xx1 + 1) #计算w
        h = np.maximum(0.0, yy2 - yy1 + 1) #计算h
        #交叉面积
        inter = w * h       
        #计算iou
        ovr = inter / (areas[i] + areas[order[1:]] - inter)
        """
        保留重叠面积小于threshold的
        np.where的返回值是tuple
        np.where(condition, x, y) 满足条件(condition)，输出x，不满足输出y
        """
        inds = np.where(ovr <= thresh)[0]
        #order里面只保留与窗口i交叠面积小于threshold的那些窗口，由于ovr长度比order长度少1(不包含i)，所以inds+1对应到保留的窗口
        order = order[inds + 1]
    return keep
```



```
Soft-NMS
```

**算法逻辑:**
输入:

- bboxes: 坐标矩阵, 每个边框表示为 [x1, y1, x2, y2]
- scores: 每个 box 对应的分数, 在 Soft-NMS 中, scores 会发生变化(**对外部变量也有影响**)
- iou_thresh: 交并比的最低阈值
- sigma2: 使用 gaussian 函数的方差, sigma2 代表 σ2σ2
- score_thresh: 最终分数的最低阈值
- method: 使用的惩罚方法, 1 代表线性惩罚, 2 代表高斯惩罚, 其他情况代表默认的 NMS

返回值: 最终留下的 boxes 的 index, 同时, scores 值也已经被改变.
算法流程:

1. 在 bboxes 之后添加对于的下标[0, 1, 2…], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标
2. 计算每个 box 自身的面积
3. **对于每一个下标 ii**, 找出 i 后面的最大 score 及其下标, 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大.
4. 计算 IoU
5. 根据用户选定的方法更新 scores 的值
6. 以上过程循环 NN 次后(NN 为总边框的数量), 将最终得分大于最低阈值的下标返回, 根据下标获取最终存留的 Boxes, **注意, 此时, 外部 scores 的值已经完成更新, 无需借助下标来获取.**

![img](J:\Main Project\Computer-Vison\MyNote\image\v2-17d64df1108abd9794a9305828160825_720w.jpg)

```
import numpy as np

def soft_nms(bboxes, scores, iou_thresh=0.3, sigma2=0.5, score_thresh=0.001, method=2):
    # 在 bboxes 之后添加对于的下标[0, 1, 2...], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标
    N = bboxes.shape[0] # 总的 box 的数量
    indexes = np.array([np.arange(N)])  # 下标: 0, 1, 2, ..., n-1
    bboxes = np.concatenate((bboxes, indexes.T), axis=1) # concatenate 之后, bboxes 的操作不会对外部变量产生影响

    # 计算每个 box 的面积
    x1 = bboxes[:, 0]
    y1 = bboxes[:, 1]
    x2 = bboxes[:, 2]
    y2 = bboxes[:, 3]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)

    for i in range(N):
        # 找出 i 后面的最大 score 及其下标
        pos = i + 1
        if i != N-1:
            maxscore = np.max(scores[pos:], axis=0)
            maxpos = np.argmax(scores[pos:], axis=0)
        else:
            maxscore = scores[-1]
            maxpos = 0

        # 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大
        if scores[i] < maxscore:
            bboxes[[i, maxpos + i + 1]] = bboxes[[maxpos + i + 1, i]]
            scores[[i, maxpos + i + 1]] = scores[[maxpos + i + 1, i]]
            areas[[i, maxpos + i + 1]] = areas[[maxpos + i + 1, i]]

        # IoU calculate
        xx1 = np.maximum(bboxes[i, 0], bboxes[pos:, 0])
        yy1 = np.maximum(bboxes[i, 1], bboxes[pos:, 1])
        xx2 = np.minimum(bboxes[i, 2], bboxes[pos:, 2])
        yy2 = np.minimum(bboxes[i, 3], bboxes[pos:, 3])
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        intersection = w * h
        iou = intersection / (areas[i] + areas[pos:] - intersection)

        # Three methods: 1.linear 2.gaussian 3.original NMS
        if method == 1:  # linear
            weight = np.ones(iou.shape)
            weight[iou > iou_thresh] = weight[iou > iou_thresh] - iou[iou > iou_thresh]
        elif method == 2:  # gaussian
            weight = np.exp(-(iou * iou) / sigma2)
        else:  # original NMS
            weight = np.ones(iou.shape)
            weight[iou > iou_thresh] = 0

        scores[pos:] = weight * scores[pos:]

    # select the boxes and keep the corresponding indexes
    inds = bboxes[:, 4][scores > score_thresh]
    keep = inds.astype(int)
    return keep

# boxes and scores
boxes = np.array([[200, 200, 400, 400], [220, 220, 420, 420],
                  [240, 200, 440, 400], [200, 240, 400, 440],
                  [1, 1, 2, 2]], dtype=np.float32)
boxscores = np.array([0.9, 0.8, 0.7, 0.6, 0.5], dtype=np.float32)
index = soft_nms(boxes, boxscores, method=2)
print(index) # 按照 scores 的排序指明了对应的 box 的下标
print(boxes[index])
print(boxscores) # 注意, scores 不需要用 index 获取, scores 已经是更新过的排序 scores
```



### 23.RCNN系列模型的区别

<img src="J:\Main Project\Computer-Vison\MyNote\image\v2-a50d903b343c70e679392dd01ca9288c_720w.jpg" alt="img" style="zoom: 200%;" />

### 24.ArcFace Loss

利用margin来扩大不同类之间距离的损失函数

ArchFace中是直接在角度空间（angular space）中最大化分类界限，而CosineFace是在余弦空间中最大化分类界限

![[公式]](J:\Main Project\Computer-Vison\MyNote\image\equation-1589457396643.svg)

### 25.Dropout

在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征

**（1）取平均的作用**

dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。

训练很多不同的网络

**（2）减少神经元之间的过度依赖**

迫使网络去学习更加鲁棒的特征

### 26.L1和L2范数各有什么特点以及相应的原因？

L1范数更容易产生稀疏的权重，L2范数更容易产生分散的权重



# 一、机器学习

## 1.SVM实现多分类

* 间接法：主要是通过组合多个二分类器来实现多分类器的构造

  [`SVC`](https://www.studyai.cn/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) 和 [`NuSVC`](https://www.studyai.cn/modules/generated/sklearn.svm.NuSVC.html#sklearn.svm.NuSVC) 实现了 “one-against-one” 方法 (Knerr et al., 1990) 用于解决多类别分类问题。 如果 `n_class` 是类的数量，那么总共需要构建 `n_class * (n_class - 1) / 2` 个分类器，其中每一个分类器都是在数据上训练得到的两类分类器。

# 二、网络结构

## 1.FPN的结构

特征金字塔网络 Feature Pyramid Networks

**顶层特征通过上采样（最近邻插值）和底层特征做融合**，而且每层都是独立预测的（足够底层的特征对于检测小物体是很有帮助的）

![img](J:\Main Project\Computer-Vison\MyNote\image\v2-3af297d1950b57041f45658371779489_b.jpg)

**算法大致结构**

**一个自底向上的线路，一个自顶向下的线路，横向连接（lateral connection）**。图中放大的区域就是横向连接，这里1*1的卷积核的主要作用是减少卷积核的个数，也就是减少了feature map的个数，并不改变feature map的尺寸大小。

**基于FPN的RPN是怎么训练的**

在FPN的每个融合后特征图的每一层上都接一个RPN子网（3*3卷积和2个并列的1\*1卷积），确定RPN子网的正负anchor box样本，再计算各预测层上RPN的anchor box分类和回归损失。

# 三、正则化方法

## 1.DropBlock

dropout 通常对全连接层很有效，对卷积层效果甚微。

![img](J:\Main Project\Computer-Vison\MyNote\image\v2-792396f4c02168c5bf05db43a1181b32_b.jpg)

图1：（b）（c）中绿色区域主要蕴含了图像的语义信息，也就是狗所在的主要区域，通过图b的方式随机dropout效果并不好，因为相邻单元也包含了相关信息。按照图C的方式，移除整块区域，例如整个头或者脚，这样可以强制剩余单元学习到用于分类的特征。

## 2.Dropout

在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征

**（1）取平均的作用**

dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。

训练很多不同的网络

**（2）减少神经元之间的过度依赖**

迫使网络去学习更加鲁棒的特征



## 3.其他Dropout方法

![image-20200519185758643](J:\Main Project\Computer-Vison\MyNote\image\image-20200519185758643.png)

## 4.Batch Normalization

BN在深层神经网络的作用非常明显：若神经网络训练时遇到收敛速度较慢，或者“梯度爆炸”等无法训练的情况发生时都可以尝试用BN来解决。同时，常规使用情况下同样可以加入BN来加速模型训练，甚至提升模型精度。

BN 是一种**正则化**方法（减少泛化误差），主要作用有：

- **加速网络的训练**（缓解梯度消失，支持更大的学习率）
- **防止过拟合**
- 降低了**参数初始化**的要求。

![TIM截图20180903222433](J:\Main Project\Computer-Vison\MyNote\image\TIM截图20180903222433.png)

# 四、激活函数

## 1.ReLu

<img src="J:\Main Project\Computer-Vison\MyNote\image\v2-886da65a9f27b8b0952fa1a4d3e26c38_b.jpg" alt="img" style="zoom:150%;" />

## 2.Leaky ReLU

<img src="J:\Main Project\Computer-Vison\MyNote\image\v2-7f22822e188109523570ebf9e8de5e4e_b.jpg" alt="img" style="zoom:150%;" />

# 五、损失函数

## 1.Dice Loss 医学影像分割

# 六、语义分割

## 1.FCN

FCN 的思想很直观，即直接进行像素级别端到端（end-to-end）的语义分割，它可以基于主流的深度卷积神经网络模型（CNN）来实现。正所谓‘全卷积神经网络‘，在FCN中，传统的全连接层 fc6 和 fc7 均是由卷积层实现，而最后的 fc8 层则被替代为一个 **21 通道**（channel）的 1x1 卷积层，作为网络的最终输出。之所以有 21 个通道是因为 PASCAL VOC 的数据中包含 21 个类别（20个「object」类别和一个「background」类别）



下图为 FCN 的网络结构，若原图为 H×W×3，在经过若干堆叠的卷积和池化层操作后可以得到原图对应的响应张量（Activation tensor）[![clip_image001](J:/Main Project/Computer-Vison/MyNote/image/1139079-20170621162544007-233703012.png)](http://images2015.cnblogs.com/blog/1139079/201706/1139079-20170621162543570-1328652783.png) ，其中，[![clip_image002](J:/Main Project/Computer-Vison/MyNote/image/1139079-20170621162544866-658506214.png)](http://images2015.cnblogs.com/blog/1139079/201706/1139079-20170621162544585-1672214780.png) 为 i 第 层的通道数。可以发现，**由于池化层的下采样作用，使得响应张量的长和宽远小于原图的长和宽，这便给像素级别的直接训练带来问题**。



为了解决下采样带来的问题，**FCN 利用双线性插值将响应张量的长宽上采样到原图大小**，另外为了更好的预测图像中的细节部分，**FCN 还将网络中浅层的响应也考虑进来**。具体来说，就是将 Pool4 和 Pool3 的响应也拿来，分别作为模型 FCN-16s 和 FCN-8s 的输出，与原来 FCN-32s 的输出结合在一起做最终的语义分割预测（如下图所示）。![image](J:/Main Project/Computer-Vison/MyNote/image/1139079-20170621163041476-975958559.png)

![image](J:/Main Project/Computer-Vison/MyNote/image/1139079-20170621163041882-328871918.png)

**影响语言分割的像素精度的主要原因是池化层的下采样操作**，由下图可以看出FCN-32s使用FCN 的最后一层卷积和池化的输出，该模型的下采样倍数最高，其对应的语义分割结果最为粗略；而 FCN-8s 则因下采样倍数较小可以取得较为精细的分割结果。

![image](J:/Main Project/Computer-Vison/MyNote/image/1139079-20170621163044570-1438981130-1567156775830.png)

## 2.deeplab v3+相比于deeplab v2的区别在于什么

deeplab v2也是基于encoder和decoder架构的，但是后面有连接CRF条件随机场，而deeplab v3+没有了条件随机场，deeplab v3+的亮点之处在于引入了ASPP空洞卷积模块和同步的BN

## 3.deeplab v3+损失函数CrossEntropyLoss

如果是做语义分割任务是得到一张【h,w】的语义图，那么input=【n,c,h,w】target=【n,h,w】

pytorch 损失函数需要把标签为255的忽略，有些数据集标注有白色描边（VOC 2012），不代表任何实际类别

```
nn.CrossEntropyLoss(ignore_index=255, reduction='mean')
```

## 4.实时语义分割

实时性语义分割算法进行了总结，发现当前主要有三种加速方法：1) 通过 Crop 或者 Resize 限制输入图片进而减少计算量；2) 减少网络通道数，尤其是 Early Stage；3) 还有像 ENet 类似的方法直接丢掉最后一个 Stage，如图10(a)所示。

# 其他

## 1.PyTorch Hook

* Variable 的 hook   torch.autograd.Variable.**register_hook** 
* Module的hook
  * torch.nn.Module.**register_backward_hook**
  * torch.nn.Module.**register_forward_hook**


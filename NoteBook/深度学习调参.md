### 1.Adam和SGD

Adam：比较傻瓜式，可以自动调节学习率（初始学习率也不能太大，只是施加一个惯性？）。不追求极致的和初学者能用它把模型训练到一个比较满意的效果。

SGD：一般框架中默认的优化器，适合要求比较高的模型训练。普遍适用于各种数据集，一般给个较大的bash_lr训练一段时间后再降低进行训练。

**推荐做法：模型好且快速收敛的方法**
**用adam训练一段时间，然后用sgd继续训练提高模型精度。**

使用大的学习率，只要不发散就行

### 2.sklearn中的网格搜索自动调参

GridSearchCV 适用于小数据

grid.fit()：运行网格搜索
grid_scores_：给出不同参数情况下的评价结果
best_params_：描述了已取得最佳结果的参数的组合
best_score_：成员提供优化过程期间观察到的最好的评分

### 3.原作者竟把ReLU放在了BN前，把线性整流放在批归一化前面，会影响BN对方差的调整